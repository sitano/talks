Go Memory Model
Jule, 2018
Tags: go, memory, model

Ivan Prisyazhnyy
Software Engineer
@JohnKoepi

* Opinions are my own

Anything on this or any subsequent slides may be a lie. Do
not base your decisions on this talk. If you do, ask for
professional help.

: Do you like statements when people do not hold any responsibility?

* A memory model?

A thing from

.link https://golang.org/ref/mem

version of May 31, 2014

* Why should we care?

.code mm/print_ab.go /START OMIT/,/END OMIT/

- Is that correct program?
- What are possible outcomes?

* Why should we care?

.code mm/print_ab.go /START OMIT/,/END OMIT/

- Is that correct program?
- What are possible outcomes?
- Is (2, 0) a possible outcome?

* Why should we care?

.code mm/wait_idiom.go /START OMIT/,/END OMIT/

- Is that correct program?
- What are possible outcomes?

* What is a correct program?

- Execution traces - histories,
- Behaviours - the way in which program acts,
- Outcomes - results.

* Race Condition Free

- A program must be correctly synchronized to avoid the kinds of counterintuitive behaviors that can be observed when code is reordered.
- A program is correctly synchronized if and only if all sequentially consistent executions are free of data races.
- If a program is correctly synchronized, then all executions of the program will appear to be sequentially consistent

* Race Condition

A race condition is the behavior of the system where the output
is dependent on the sequence or timing of other uncontrollable events.
It becomes a bug when events do not happen in the order the programmer intended.

- The correctly synchronized program is data race free

* Sequential Consistency

Sequential Consistency (SC): (def.)
¬´...the result of any execution is the same as if the operations of all the processors were executed in some sequential order, and the operations of each individual processor appear in this sequence in the order specified by its program¬ª

- If a program has no data races, then all executions of the program will appear to be sequentially consistent.

* How can we understand that the program is correct?

Just make it DRF (data race free).

- In order of doing so, you must made it correct under a memory model.
- Memory models specifies which executions of the program are correct.

* How can we understand that the program is correct?

> Use memory model, Luke.

- which programs are valid
- what those valid programs can do
- therefore what programmers can expect
- therefore what compiler writers must ensure / can do

* But why there are Race Conditions in the first place?

* A Fairy Tale

In a past good days everything was simple.

Once upon a time‚Ä¶

How do you make a program faster?

    Buy newer hardware.

Is a hardware or compiler optimization valid?

    Yes, if valid programs don‚Äôt change behavior.
    (And most programs are valid.)

* An Evil Twist

Hardware engineer‚Äôs magic spells stopped working.

    New magic spell: stamp out more and more cores.

Compiler and operating system engineers give us multithreaded programming.

Now hardware, compiler optimizations change program behaviors.

- multiple issue of instructions
- out-of-order execution
- speculative execution
- optimizations on various levels
- multiple core, caches

* How can we get along?

‚ÄúValid optimizations do not change the behavior of valid programs.‚Äù

back to our code example:

.code mm/wait_idiom.go /START OMIT/,/END OMIT/

Can it ever print 0?

* Can it ever print 0?

‚ÄúIt depends.‚Äù

.code mm/wait_idiom.go /START OMIT/,/END OMIT/

In x86 assembly, no.
In ARM/POWER assembly, yes.
In most C compilers (even on x86), yes (or maybe it won‚Äôt even finish).

* ‚ÄúIt depends‚Äù is not a happy ending

- Hardware
- Compiler
- Program

* Hardware Memory Models

* Litmus Test: Message Passing

         var x, y int
    ----------------------
        T1    |      T2
    ----------------------
      x = 1   |  r1 = y
      y = 2   |  r2 = x

Can this program see r1 = 1, r2 = 0?

* Message Passing w/ Sequential Consistency

.html mm/sce_msg_pass.html

Can this program see r1 = 1, r2 = 0?

On sequentially consistent hardware: *no*.

* Sequentially Consistent Hardware

.image mm/hw_sc.png

Maranget et al.,
.link https://www.cl.cam.ac.uk/~pes20/ppc-supplemental/test7.pdf ‚ÄúA Tutorial Introduction to the ARM and POWER Relaxed Memory Models‚Äù

* x86 Hardware (Total Store Order)

.image mm/hw_sto.png _ 650

Maranget et al.,
.link https://www.cl.cam.ac.uk/~pes20/ppc-supplemental/test7.pdf ‚ÄúA Tutorial Introduction to the ARM and POWER Relaxed Memory Models‚Äù

* Litmus Test: Message Passing

         var x, y int
    ----------------------
        T1    |      T2
    ----------------------
      x = 1   |  r1 = y
      y = 2   |  r2 = x

Can this program see r1 = 1, r2 = 0?
On x86 (or other TSO): *no*.

    Thread 1‚Äôs writes are observed by other threads in original order.

* Litmus Test: Message Passing

         var x, y int
    ----------------------
        T1    |      T2
    ----------------------
      x = 1   |  r1 = y
      y = 2   |  r2 = x

Can this program see r1 = 0, r2 = 0?
On sequentially consistent hw: *no*.
On x86 (or other TSO): *yes*!

    Thread 1‚Äôs local writes are not immediately visible in Thread 2 (and vice versa).

* Memory Fences

         var x, y int
    ----------------------
        T1    |      T2
    ----------------------
      x = 1   |  r1 = y
      *fence* |  *fence*
      y = 2   |  r2 = x

Can this program see r1 = 0, r2 = 0? No.

Memory fence ensures Thread 1‚Äôs write is globally visible before Thread 1‚Äôs read,
and vice versa.

Glossing over details.

* Litmus Test: Independent Reads of Indep. Writes

    Thread 1 | T2    | T3     | T4
    ---------------------------------
    x = 1    | y = 1 | r1 = x | r3 = y
                       r2 = y | r4 = x

Can this program see r1 = 1, r2 = 0, r3 = 1, r4 = 0?

Can Thread 3 see x change before y but Thread 4 see the opposite?

On sequentially consistent hw: no.
On x86 (or other TSO): no.

There is a total order over all stores to main memory.

* ARM/POWER Hardware

.image mm/hw_arm.png _ 450

Maranget et al.,
.link https://www.cl.cam.ac.uk/~pes20/ppc-supplemental/test7.pdf ‚ÄúA Tutorial Introduction to the ARM and POWER Relaxed Memory Models‚Äù

* Litmus Test: Message Passing

         var x, y int
    ----------------------
        T1    |      T2
    ----------------------
      x = 1   |  r1 = y
      y = 2   |  r2 = x

Can this program see r1 = 1, r2 = 0?
On x86 (or other TSO): *no*.
On ARM/POWER: yes!

    Thread 1‚Äôs writes may not be observed by other threads in original order.

* Litmus Test: Store Buffering

         var x, y int
    ----------------------
        T1    |      T2
    ----------------------
      x = 1   |  y = 1
      r1 = y  |  r2 = x

Can this program see r1 = 0, r2 = 0?
On sequentially consistent hw: no.
On x86 (or other TSO): yes!
On ARM/POWER: yes!

    Thread 1‚Äôs local writes are not immediately visible in Thread 2 (and vice versa).

* Litmus Test: Independent Reads of Indep. Writes

    Thread 1 | T2    | T3     | T4
    ---------------------------------
    x = 1    | y = 1 | r1 = x | r3 = y
                       r2 = y | r4 = x

Can this program see r1 = 1, r2 = 0, r3 = 1, r4 = 0?

Can Thread 3 see x change before y but Thread 4 see the opposite?

On sequentially consistent hw: no.
On x86 (or other TSO): no.
On ARM/POWER: yes!

    Different threads may receive different writes in different orders.

* Litmus Test: Coherence

    Thread 1 | T2    | T3     | T4
    ---------------------------------
    x = 1    | y = 2 | r1 = x | r3 = x
                       r2 = x | r4 = x

Can this program see r1 = 1, r2 = 2, r3 = 2, r4 = 1?

Can Thread 3 see x change before y but Thread 4 see the opposite?

On sequentially consistent hw: no.
On x86 (or other TSO): no.
On ARM/POWER: yes!

    Different threads may receive different writes in different orders.

* Weak Ordering

‚ÄúLet a synchronization model be a set of constraints on memory accesses that
specify how and when synchronization needs to be done.

Hardware is weakly ordered with respect to a synchronization model if and only if
it appears sequentially consistent to all software that obey the synchronization
model.‚Äù

.link http://pages.cs.wisc.edu/~markhill/papers/isca90_drf0.pdf Adve and Hill, ‚ÄúWeak Ordering - A New Definition‚Äù (1990)

: The 13 possible strict weak orderings on a set of three elements {a, b, c}. The only partially ordered sets are coloured, while totally ordered ones are in black. Two orderings are shown as connected by an edge if they differ by a single dichotomy.
: In mathematics, especially order theory, a weak ordering is a mathematical formalization of the intuitive notion of a ranking of a set, some of whose members may be tied with each other. Weak orders are a generalization of totally ordered sets (rankings without ties) and are in turn generalized by partially ordered sets and preorders.

: Strict weak orderings
: A strict weak ordering is a binary relation < on a set S that is a strict partial order (a transitive relation that is irreflexive, or equivalently,[6] that is asymmetric) in which the relation "neither a < b nor b < a" is transitive.[1] Therefore, a strict weak ordering has the following properties:

: - For all x in S, it is not the case that x < x (irreflexivity).
: - For all x, y in S, if x < y then it is not the case that y < x (asymmetry).
: - For all x, y, z in S, if x < y and y < z then x < z (transitivity).
: - For all x, y, z in S, if x is incomparable with y (neither x < y nor y < x hold), and y is incomparable with z, then x is incomparable with z (transitivity of incomparability).
: This list of properties is somewhat redundant, in that asymmetry implies irreflexivity, and in that irreflexivity and transitivity together imply asymmetry.

: .link https://en.wikipedia.org/wiki/Weak_ordering

: Less formally, a less formal definition (Weak Consistency):

: Definition 1: In a multiprocessor system,storage accesses are weakly ordered if (1) accesses to global synchronizing variables are strongly ordered, (2) no access to a synchronizing variable is issued by a processor before all previous global data accesses have been globally performed, and if (3) no access to global data is issued by a processor before a previous access to a synchronizing variable has been globally performed.*

* Data-Race-Free (DRF)

Synchronization operations are (to hardware) recognizably different from ordinary
operations.

A program is data-race-free if for all idealized SC executions, any two ordinary
memory accesses to the same location from different threads are either:

- both reads
- or separated by synchronization operations: one _happens-before_ the other

* Data-Race-Free

.image mm/drf_free.png _ 600

.link http://pages.cs.wisc.edu/~markhill/papers/isca90_drf0.pdf Adve and Hill, ‚ÄúWeak Ordering - A New Definition‚Äù (1990)

* Not Data-Race-Free

.image mm/drf_non_free.png _ 550

.link http://pages.cs.wisc.edu/~markhill/papers/isca90_drf0.pdf Adve and Hill, ‚ÄúWeak Ordering - A New Definition‚Äù (1990)

* Hardware weakly ordered by DRF

‚ÄúHardware is weakly ordered with respect to [DRF] if and only if it appears
sequentially consistent to all software that obey [DRF].‚Äù

.link https://herbsutter.com/2012/08/02/strong-and-weak-hardware-memory-models/

* Hardware weakly ordered by DRF when...

    - Intra-processor dependencies are preserved
    - All writes to same location have a global total order (coherence)
    - All sync operations to same location have a global total order
        - for S1 before S2, all of S1 must complete before any of S2 starts.
    - A new access is not generated by a processor until previous sync operations
    are committed.
    - Once a sync operation S by processor P is committed, no other sync
    operations on the same location can commit until:
        - all reads by P before S must be committed
        - all writes by P before S must be globally performed

by definition of Weak Consistency

* Hardware weakly ordered by DRF

Basically everything, given appropriate synchronization implementations

- Earlier hardware models
- VAX
- x86
- ARM/POWER

Guarantee that DRF implies appearance of SC: DRF-SC.

* Compilers

Significant freedom to rewrite code.
Significant gaps in knowledge of execution.

    w = 1
    x = 2
    r1 = y
    r2 = z

Compiled code fails (answers *yes!* to) every litmus test we‚Äôve seen,
including coherence!

* Compiler Optimizations

Is this a valid optimization?

.html mm/compiler_opt_1.html

Compiler and language must be involved in multithreaded guarantees.

.link http://www.hpl.hp.com/techreports/2004/HPL-2004-209.pdf Boehm, ‚ÄúThreads Cannot be Implemented as a Library‚Äù (2004):

* Weak Ordering?

‚ÄúHardware is weakly ordered with respect to a synchronization model if and only if
it appears sequentially consistent to all software that obey the synchronization
model.‚Äù

> Why not a programming language (implementation)?

* Memory model

* Theory

Memory model:

- defines which executions of a program are legal
- thus, allows to understand which optimizations are correct

"A program is correctly synchronized if and only if all sequentially consistent executions are free of data races."

"If a program is correctly synchronized, then all executions of the program will appear to be sequentially consistent (¬ß17.4.3)."

.link https://en.wikipedia.org/wiki/Memory_model_(programming)
.link https://docs.oracle.com/javase/specs/jls/se8/html/jls-17.html#jls-17.4

* Theory

- Program => Executions => Outcomes,
- `Program` consists of `Actions`,
- `Executions` consists of sequential traces of a program `Actions`,
- `Behaviours` may be incorrect and counterintuitive if something wrong.

Executions are the behaviors of the abstract machine, not
the behavior of final implementation. They define all possible
ways the program can possibly execute.

: Executions in JMM:

: An execution E is described by a tuple < P, A, po, so, W, V, sw, hb >, comprising:

: P - a program
: A - a set of actions
: po - program order, which for each thread t, is a total order over all actions performed by t in A
: so - synchronization order, which is a total order over all synchronization actions in A
: W - a write-seen function, which for each read r in A, gives W(r), the write action seen by r in E.
: V - a value-written function, which for each write w in A, gives V(w), the value written by w in E.
: sw - synchronizes-with, a partial order over synchronization actions
: hb - happens-before, a partial order over actions

: Note that the synchronizes-with and happens-before elements are uniquely determined by the other components of an execution and the rules for well-formed executions (¬ß17.4.7).
: An execution is happens-before consistent if its set of actions is happens-before consistent (¬ß17.4.5).

: Well-Formed Executions
: We only consider well-formed executions. An execution E = < P, A, po, so, W, V, sw, hb > is well formed if the following are true:
: 1. Each read sees a write to the same variable in the execution.
:    All reads and writes of volatile variables are volatile actions. For all reads r in A, we have W(r) in A and W(r).v = r.v. The variable r.v is volatile if and only if r is a volatile read, and the variable w.v is volatile if and only if w is a volatile write.
: 2. The happens-before order is a partial order.
:    The happens-before order is given by the transitive closure of synchronizes-with edges and program order. It must be a valid partial order: reflexive, transitive and antisymmetric.
: 3. The execution obeys intra-thread consistency.
:    For each thread t, the actions performed by t in A are the same as would be generated by that thread in program-order in isolation, with each write w writing the value V(w), given that each read r sees the value V(W(r)). Values seen by each read are determined by the memory model. The program order given must reflect the program order in which the actions would be performed according to the intra-thread semantics of P.
: 4. The execution is happens-before consistent (¬ß17.4.6).
: 5. The execution obeys synchronization-order consistency.
:    For all volatile reads r in A, it is not the case that either so(r, W(r)) or that there exists a write w in A such that w.v = r.v and so(W(r), w) and so(w, r).

: + Causality requirements $17.4.8

* Theory

Executions ‚âà Actions ‚à™ Orders ‚à™ Consistency Rules

Actions:

- Read (Load)
- Write (Store)
- Synchronization actions: volatile rw (seq_cst), acq/rel, lock/unlock, synthetic (first action of the goroutine), actions that start threads/goroutines or destroys thema
- External actions

: External Actions. An external action is an action that may be observable outside of an execution, and has a result based on an environment external to the execution.

- Divergent actions

: Thread divergence actions (¬ß17.4.9). A thread divergence action is only performed by a thread that is in an infinite loop in which no memory, synchronization, or external actions are performed. If a thread performs a thread divergence action, it will be followed by an infinite number of thread divergence actions.

: Thread divergence actions are introduced to model how a thread may cause all other threads to stall and fail to make progress.

* Theory

Executions ‚âà Actions ‚à™ Orders ‚à™ Consistency Rules

Orders:

- Program Order (PO)

: Among all the inter-thread actions performed by each thread t, the program order of t is a total order that reflects the order in which these actions would be performed according to the intra-thread semantics of t.

- Synchronization Order (SO)

: A synchronization order is a total order over all of the synchronization actions of an execution. For each thread t, the synchronization order of the synchronization actions (¬ß17.4.2) in t is consistent with the program order (¬ß17.4.3) of t.

- Happens-Before (HB)

: If we have two actions x and y, we write hb(x, y) to indicate that x happens-before y.
: If x and y are actions of the same thread and x comes before y in program order, then hb(x, y).
: There is a happens-before edge from the end of a constructor of an object to the start of a finalizer (¬ß12.6) for that object.
: If an action x synchronizes-with a following action y, then we also have hb(x, y).
: If hb(x, y) and hb(y, z), then hb(x, z).

"A set of synchronization edges, S, is sufficient if it is the minimal set such that the transitive closure of S with the program order determines all of the happens-before edges in the execution. This set is unique."

.link https://docs.oracle.com/javase/specs/jls/se8/html/jls-17.html#jls-17.4 JMM ($17.4.5)

* Theory

Executions ‚âà Actions ‚à™ Orders ‚à™ Consistency Rules

Consistency Rules:

: A consistency rule that affects values observed by the actions.

- PO consistency - total order of intra-thread actions. PO is consistent with the source code order in the original program.

: PO consistency affects the structure of the execution.

- SO consistency - covers all synchronization actions. SO is a total order of all SA.
- SO - PO consistency - SW = SO + SO-PO. SW => Coherence (reads see only the latest write in). SW is a partial order.

: Coherence (def.) : The writes to the single memory location appear to be in a total order consistent with program order

- HB consistency - HB is a transitive closure over the union of PO and SW. HB is partial order too.

: HB consistency: reads observe either: the last write in hb order, or any other write, not ordered by hb.

* Theory

- HB + magic => causality
- SO ‚âà Sequential Consistency

: Sequential Consistency (SC): (def.) ¬´...the result of any execution is the same as if the operations of all the processors were executed in some sequential order, and the operations of each individual processor appear in this sequence in the order specified by its program¬ª  Sequential Consistency is not always needed:

Sequential Consistency is not always needed:

- Extreme costs to get it in distributed systems
- Most examples so far were fine with just Release/Acquire!

: see JMM: Example 17.4.8-1. Happens-before Consistency Is Not Sufficient

* Theory

- A program is correctly synchronized if and only if all sequentially consistent executions are free of data races.
- If a program is correctly synchronized, then all executions of the program will appear to be sequentially consistent

* Why?

    int a = 0
    -----------------
    a = 1   |   a = 2
    r1 = a  |

    ----------------------------------------------------

    ùë§(ùëé, 1) ‚àíhb‚àí> ùëü(ùëé) : 1 ... ùë§(ùëé, 2)
    ùë§(ùëé, 1) -hb‚àí> ùëü(ùëé) : 2 ... ùë§(ùëé, 2)      ùëü1 ‚àà {1, 2}

    Original -MM-> {Executions} -yield-> {Outcomes}
    Program                                 ^
      |                                     | (subset of)
      \-impl-> {Impls subset} -yields-> {Results}

                mov 1 ‚Üí (a)                 ùëü1 ‚àà {1}
                mov 1 ‚Üí (r1)

* Go

Is something at [[https://golang.org/ref/mem][golang/mem]] a spec?

* Go

Is something at [[https://golang.org/ref/mem][golang/mem]] a spec?

- No

* What's the point?

Two purposes:

- Make guarantees for programmers.
- Allow compilers/hardware to make certain changes to programs.

Ideally, perfectly balanced. In practice, more conservative: might do neither.

Explicit concern: Leave room for future refinement, refraining from:

- making debatable guarantees to programmers
- allowing compilers/hardware to make debatable changes to programs

* What we are given?

"The Go memory model specifies the conditions under which reads of a variable in one goroutine can be guaranteed to observe values produced by writes to the same variable in a different goroutine."

Nothing about consistency...
or race conditions

"Programs that modify data being simultaneously accessed by multiple goroutines must serialize such access."

because hardware and compiler may do something...

* How to serialize access?

Use happens-before:

- PO
- HB
- SO, SO-PO

* What Synchronization-With order do we have?

- If p imports q, q‚Äôs init happens before p‚Äôs.
- Package main‚Äôs init happens before main.main
- The go statement happens before the created goroutine‚Äôs execution
- A send (or close) on a channel happens before the receive
- Unlock happens before subsequent Lock

TODO: examples

* Hmmm...

> Unlock happens before subsequent Lock

* How the Mutex works as a memory barrier?

SW is given in terms of language derivatives.

* How the Mutex is implemented?

    // Fast path: grab unlocked mutex.
    if atomic.CompareAndSwapInt32(&m.state, 0, mutexLocked) {...}

    // Long path:
    runtime_canSpin() -> runtime_doSpin()
    + starvation detection: runtime_nanotime()-waitStartTime > starvationThresholdNs
    + lock fairness with LIFO/Q semaphore runtime_SemacquireMutex(&m.sema, lifo: waitStartTime != 0)
    + race detection

sync/mutex is implemented with sync/atomic only.

* How the Mutex works as a memory barrier?

the sync/atomics works as a memory barriers.

* What about sync/atomic in mm?

?

* What about sync/atomic?

Package sync/atomic is conspicuously missing.

Proposal: match Java volatile and C++ memory_order_seq_cst.

- An atomic write happens before an atomic read that observes the write.
- The outcome of atomic operations must be consistent with a total order over all atomic operations in the program.

.link https://github.com/golang/go/issues/5045 doc: define how sync/atomic interacts with memory model #5045

TODO: examples of atomics litmus tests

* How atomics works as a memory barrier?

on x86/amd64

    TEXT ¬∑CompareAndSwapUint32(SB),NOSPLIT,$0-17
        MOVQ	addr+0(FP), BP
        MOVL	old+8(FP), AX
        MOVL	new+12(FP), CX
        LOCK                    <---------
        CMPXCHGL	CX, 0(BP)
        SETEQ	swapped+16(FP)
        RET

they use LOCK-prefixed instructions like CMPXCHG, XCHGQ, XADDL

* How atomics works as a memory barrier?

on x86/amd64

Section 8.2.5:

    The I/O instructions, locking instructions, the LOCK prefix, and serializing instructions force stronger ordering on the processor.

Also from 8.2.5:

    "Like the I/O and locking instructions, the processor waits until all previous instructions have been completed and all buffered writes have been drained to memory before executing the serializing instruction."

.link https://stackoverflow.com/questions/50280857/do-locked-instructions-provide-a-barrier-between-weakly-ordered-accesses
.link https://peeterjoot.wordpress.com/2009/12/04/intel-memory-ordering-fence-instructions-and-atomic-operations/

* How atomics works as a memory barrier?

on arm64

    TEXT ¬∑CompareAndSwapUint32(SB),NOSPLIT,$0-17
        MOVD	addr+0(FP), R0
        MOVW	old+8(FP), R1
        MOVW	new+12(FP), R2
    again:
        LDAXRW	(R0), R3     <------------ implicit
        CMPW	R1, R3
        BNE	ok
        STLXRW	R2, (R0), R3 <------------ rel/acq mem barrier
        CBNZ	R3, again
    ok:
        CSET	EQ, R0
        MOVB	R0, swapped+16(FP)
        RET

* How atomics works as a memory barrier?

on arm

    TEXT ¬∑armCompareAndSwapUint32(SB),NOSPLIT,$0-13
        ...
    casloop:
        // LDREX and STREX were introduced in ARMv6.
        LDREX	(R1), R0
        CMP	R0, R2
        BNE	casfail
        DMB_ISHST_7
        STREX	R3, (R1), R0
        CMP	$0, R0
        BNE	casloop
        MOVW	$1, R0
        DMB_ISH_7  <--------- explicit memory barrier
        MOVBU	R0, swapped+12(FP)
        RET
    casfail:
        MOVW	$0, R0
        MOVBU	R0, swapped+12(FP)
        RET

* How atomics works as a memory barrier?

on arm

- Load-Acquire (LDAR): All loads and stores that are after an LDAR in program order, and that match the shareability domain of the target address, must be observed after the LDAR.
- Store-Release (STLR): All loads and stores preceding an STLR that match the shareability domain of the target address must be observed before the STLR.
- There are also exclusive versions of the above, LDAXR and STLXR, available.

.link https://developer.arm.com/products/architecture/a-profile/docs/100941/latest/barriers
.link http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.den0024a/CEGDBEJE.html
.link https://stackoverflow.com/questions/21535058/arm64-ldxr-stxr-vs-ldaxr-stlxr
.link http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.den0024a/ch06s03s11.html ARM Cortext-A > Multi-processing systems > Synchronization

* Data races

TODO: examples of incorrect synchronization.

* Detection of data races

TODO

* Race detector implementation

TODO

* Links

- "The Go Memory Model", Version of May 31, 2014, https://golang.org/ref/mem
- "Go‚Äôs Memory Model", Russ Cox, rsc@google.com, MIT 6.824 / February 25, 2016
- "Java Memory Model Unlearning Experience", Aleksey Shipil—ëv, shade@redhat.com, @shipilev, 2018
- "Close Encounters of The Java Memory Model Kind", Aleksey Shipil—ëv, 2016
- "Java Memory Model Pragmatics (transcript)", Aleksey Shipil—ëv, 2014
- "C++ Memory Model", https://en.cppreference.com/w/cpp/language/memory_model

* Links

- [[https://github.com/golang/go/issues/5045][doc: define how sync/atomic interacts with memory model #5045]]
- [[https://stackoverflow.com/questions/50280857/do-locked-instructions-provide-a-barrier-between-weakly-ordered-accesses]]
- [[https://peeterjoot.wordpress.com/2009/12/04/intel-memory-ordering-fence-instructions-and-atomic-operations/]]
- [[https://developer.arm.com/products/architecture/a-profile/docs/100941/latest/barriers]]
- [[http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.den0024a/CEGDBEJE.html]]
- [[https://stackoverflow.com/questions/21535058/arm64-ldxr-stxr-vs-ldaxr-stlxr]]
- [[http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.den0024a/ch06s03s11.html][ARM Cortext-A > Multi-processing systems > Synchronization]]

* Quotes

TODO: ...
